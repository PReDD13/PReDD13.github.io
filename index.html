<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="ICASSP 2026">
  <meta property="og:title" content="PReDD ICASSP"/>
  <meta property="og:description" content="Dataset Distillation ICASSP"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>ICASSP PReDD</title>
  <link rel="icon" type="image/x-icon" href="static/images/PReDD.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">PReDD: Post-Distillation Refinement for Dataset Distillation</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Zhiyong Shu</a>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Jielei Wang</a>,</span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Qianxin Xia</a>,</span>
                      <span class="author-block">
                        <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Guoming Lu</a><sup>*</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">
                      The Institute of Intelligent Computing, UESTC, Chengdu, China<br>
                      Ubiquitous Intelligence and Trusted Services Key Laboratory of Sichuan Province, Chengdu, China<br>
                      ICASSP 2026
                    </span>
                    <span class="eql-cntrb">
                      <small><br><sup>*</sup>Indicates Corresponding Author</small>
                    </span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/Shuzhiyong13/PReDD" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- main graph-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- 替换为图片 -->
      <img src="static/images/main_graph.svg" alt="Main Graph" style="width: 97%; height: auto; display: block; margin: 0 auto;">
      <h2 class="subtitle has-text-centered">
        Illustration of the PReDD framework. Distilled images are encoded into the latent space of a pretrained VAE, perturbed to align with the diffusion prior, refined via truncated reverse diffusion to restore semantic fidelity without reintroducing high-frequency patterns, and decoded back into image space to produce semantically consistent samples.  
      </h2>
    </div>
  </div>
</section>
<!-- End main graph -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Dataset distillation compresses large datasets into compact synthetic subsets for efficient learning. 
            However, existing methods often rely on surrogate models, resulting in undesirable high-frequency patterns and limited cross-architecture generalization. 
            To address this issue, we introduce PReDD, 
            a training-free and <b>P</b>ost-distillation <b>Re</b>finement module that improves the quality of <b>D</b>istilled <b>D</b>atasets without retraining or modifying the original pipeline. 
            PReDD encodes distilled images into the latent space of a pretrained VAE and applies a truncated reverse diffusion process to refine them, 
            effectively suppressing surrogate-induced high-frequency patterns while preserving semantic content. 
            Our method is model-agnostic and compatible with various distillation techniques. 
            Extensive experiments show that PReDD consistently achieves state-of-the-art performance on cross-architecture evaluation, 
            demonstrating superior generalization in dataset distillation.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Motivation with four images -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Motivation and Our Contribution</h2>

    <div class="columns is-centered">
      <div class="column has-text-centered">
        <img src="static/images/high_freq_distribution_dm.svg" alt="Motivation 1" style="max-width: 100%; height: auto;">
      </div>
      <div class="column has-text-centered">
        <img src="static/images/high_freq_distribution_mtt.svg" alt="Motivation 2" style="max-width: 100%; height: auto;">
      </div>
      <div class="column has-text-centered">
        <img src="static/images/barplot_convnet.svg" alt="Motivation 3" style="max-width: 100%; height: auto;">
      </div>
      <div class="column has-text-centered">
        <img src="static/images/barplot_crossarch.svg" alt="Motivation 4" style="max-width: 100%; height: auto;">
      </div>
    </div>

    <div class="content has-text-justified mt-5">
      <p>
        As shown in Figure above, a key limitation of surrogate-driven distillation is the emergence of excessive high-frequency patterns in synthetic images. 
        We quantify these patterns using Fourier analysis by computing the ratio of spectral energy in the high-frequency band (normalized radial frequency r ≥ 0.5) and plotting its distribution across samples. Distilled datasets exhibit higher high-frequency energy than random, which correlates with degraded cross-architecture generalization. 
        In contrast, PReDD reduces these patterns, producing spectra closer to or even lower than those of randomly chosen real samples. 
        This improvement mitigates structural bias and enhances transferability across architectures.
      </p>

      <p><b>Our contributions are summarized as follows:</b></p>
      <ul>
        <li>
          Through Fourier analysis, we reveal that surrogate-driven distilled datasets exhibit 
          high-frequency patterns that hinder generalization. 
        </li>
        <li>
          By encoding distilled samples with a pre-trained VAE and applying truncated reverse diffusion, 
          PReDD suppresses high-frequency components while enhancing semantic fidelity.
        </li>
        <li>
          PReDD is modular and lightweight, easily integrated into existing pipelines, and achieves 
          state-of-the-art cross-architecture performance on ImageNet subsets.
        </li>
      </ul>
    </div>
  </div>
</section>

<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">

      <!-- 标题-->
      <h2 class="title is-3 has-text-centered">Visualization</h2>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/dm_cats_grid.jpg" alt="Meow 10ipc DM+PReDD" style="zoom: 50%;"/>
        <h2 class="subtitle has-text-centered">
          Meow 10ipc DM+PReDD
        </h2>
      </div>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
         <!-- Your image here -->
         <img src="static/images/dm_fruits_grid.jpg" alt="Fruits 10ipc DM+PReDD" style="zoom: 50%;"/>
         <h2 class="subtitle has-text-centered">
           Fruits 10ipc DM+PReDD
         </h2>
       </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/dm_woof_grid.jpg" alt="Woof 10ipc DM+PReDD" style="zoom: 50%;"/>
        <h2 class="subtitle has-text-centered">
          Woof 10ipc DM+PReDD
       </h2>
     </div>
     <div class="item">
      <!-- Your image here -->
      <img src="static/images/mtt_squawk_grid.jpg" alt="Squawk 10ipc MTT+PReDD" style="zoom: 50%;"/>
      <h2 class="subtitle has-text-centered">
        Squawk 10ipc MTT+PReDD
      </h2>
    </div>
    <div class="item">
      <!-- Your image here -->
      <img src="static/images/mtt_nette_grid.jpg" alt="Nette 10ipc MTT+PReDD" style="zoom: 50%;"/>
      <h2 class="subtitle has-text-centered">
        Nette 10ipc MTT+PReDD
      </h2>
    </div>
    <div class="item">
      <!-- Your image here -->
      <img src="static/images/mtt_yellow_grid.jpg" alt="Yellow 10ipc MTT+PReDD" style="zoom: 50%;"/>
      <h2 class="subtitle has-text-centered">
        Yellow 10ipc MTT+PReDD
      </h2>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->

<style>
  .carousel img {
    max-width: 50%;   /* 缩小到原来的一半宽度 */
    height: auto;     /* 按比例缩放 */
    display: block;   /* 让 margin 生效 */
    margin: 0 auto;   /* 居中 */
  }
</style>

<!-- Effect of Reverse Diffusion Steps + t-SNE -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">

      <div class="columns is-vcentered">

        <!-- 左半边: Ablation 图 -->
        <div class="column is-half has-text-centered">
          <img src="static/images/ablation_subplots.svg" 
               alt="Reverse Diffusion Ablation" 
               style="max-width: 80%; height: auto; display: block; margin: 0 auto;">
          <p class="is-6 has-text-grey mt-1">Effect of Reverse Diffusion Steps</p>

          <!-- 可选分析文字针对左边图 -->
          <div class="content has-text-justified mt-2">
            <p>
              As shown above, <b>MTT</b>(left) consistently favors a shallow depth (K=10) for both IPC=1 and IPC=10, 
              while <b>DM</b>(right) requires deeper refinement, peaking at K=15 for IPC=1 and K=20 for IPC=10. 
              This is due to semantic quality differences: MTT produces class-consistent samples, so shallow refinement suffices, 
              whereas DM generates weaker semantics with stronger high-frequency bias, benefiting from more reverse steps. 
              Excessively large K may oversmooth details and harm generalization.
            </p>
          </div>
        </div>

        <!-- 右半边: t-SNE 图 -->
        <div class="column is-half has-text-centered">

          <img src="static/images/t-SNE.svg" 
               alt="t-SNE Feature Visualization" 
               style="max-width: 120%; height: auto; display: block; margin: 0 auto;">
          <p class="is-6 has-text-grey mt-1">t-SNE Visualization</p>

          <div class="content has-text-justified mt-2">
            <p>
              Fig. above shows a t-SNE visualization of feature embeddings for three selected classes in ImageNet-Fruits (10 IPC). 
              Random samples are widely scattered with substantial overlaps, distilled samples are more compact but still suffer from noticeable inter-class mixing. 
              In contrast, PReDD consistently produces clusters that are both compact within each class and well separated across classes, with minimal overlaps.
            </p>
          </div>
        </div>

      </div>

    </div>
  </div>
</section>
<!-- End Effect of Reverse Diffusion Steps + t-SNE -->



<!-- Results Table (as image) -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">

      <h2 class="title is-3">Quantitative Results</h2>

      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">

          <!-- 表格截图 -->
          <img src="static/images/table_results.png" 
               alt="Quantitative Results Table" 
               style="max-width: 80%; height: auto; display: block; margin: 0 auto;"/>

          <!-- 表格说明 -->
          <p class="subtitle is-6">
            Cross-architecture Top-1 accuracy on various ImageNet subsets (IPC = 1, 10).  
            Evaluation on <b>unseen architectures</b>, including ViT-b/16, EfficientNet, ShuffleNetV2, MobileNetV2, and ResNet18. Mean ± std over 5 runs.
          </p>

          <!-- 分析段落 -->
          <div class="content has-text-justified mt-3">
            <p>
              Table above summarizes cross-architecture results on multiple ImageNet subsets under IPC=1 and 10. 
              Across all baselines, our <b>PReDD</b> consistently improves generalization on unseen architectures. 
              Gains are particularly pronounced on MTT, where improvements exceed <b>+10%</b> absolute in several settings 
              (e.g., Yellow, Nette at IPC=10). This indicates that PReDD effectively reduces surrogate-induced bias 
              and strengthens semantic consistency.
            </p>
          </div>

        </div>
      </div>

    </div>
  </div>
</section>
<!-- End Results Table -->



<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!-- BibTex citation -->
  <!-- <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section> -->
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
